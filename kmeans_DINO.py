import os
import shutil
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from tqdm import tqdm

# ========= é…ç½® =========
CSV_PATH = "all_features_dinov3.csv"  # DINOv1 ç‰¹å¾æ–‡ä»¶
IMAGE_ROOT = os.path.abspath("all_cutouts")  # å›¾åƒæ–‡ä»¶å¤¹
OUTPUT_FOLDER = "all_kmeans_new"  # èšç±»ç›®å½•
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# ========= 1. è¯»å–ç‰¹å¾ =========
df = pd.read_csv(CSV_PATH).iloc[:5000].copy()

if "filename" not in df.columns:
    raise ValueError("âŒ CSV ä¸­å¿…é¡»åŒ…å« 'filename' åˆ—")

print(f"âœ… è¯»å– {len(df)} æ¡ç‰¹å¾è®°å½•")

# ========= 2. ä¸»ç¼–å·ï¼šåªå» _exterior / _interior =========
def get_piece_id(filename):

    name = os.path.splitext(filename)[0]
    name = name.replace("_exterior", "").replace("_interior", "")
    return name.lower()

df["main_id"] = df["filename"].apply(get_piece_id)

dropped_main_ids = []

# ========= 3. æ¯ä¸ª main_id åªä¿ç•™å‰ä¸¤å¼ ï¼ˆè®¤ä¸ºæ˜¯æ­£åï¼‰ =========
def select_two_images(group):
    """
    ä¸ç®¡æ­£åï¼Œåªè¦ main_id ä¸€è‡´ â†’ ä¸€ä¸ªé™¶ç‰‡
    åªä¿ç•™å‰ä¸¤å¼ ç”¨äºèåˆ
    """
    mid = group["main_id"].iloc[0]

    if len(group) < 2:
        dropped_main_ids.append(mid)

        return pd.DataFrame([])  # å°‘äºä¸¤å¼ ä¸¢å¼ƒ

    return group.iloc[:2]  # åªä¿ç•™å‰ä¸¤å¼ 

selected_df = (
    df.groupby("main_id", group_keys=False)
      .apply(select_two_images)
      .reset_index(drop=True)
)

for mid in dropped_main_ids:
    print(mid)

print(f"âœ… è¿‡æ»¤åå‰©ä½™é™¶ç‰‡æ•°: {len(selected_df['main_id'].unique())}")

# ========= 4. ç‰¹å¾åˆ— =========
feature_cols = [c for c in df.columns if c not in ["filename", "main_id"]]

# ========= 5. æ‹¼æ¥ç‰¹å¾ï¼ˆä¸¤å¼ å›¾ç®€å•ç›¸åŠ /å¹³å‡ï¼‰ =========
def fuse_features(group):
    """
    ä¸¤å¼ å›¾åƒ â†’ ç‰¹å¾æ‹¼æ¥ï¼ˆconcatï¼‰
    æ³¨æ„ï¼šgroup æ­£å¥½ 2 å¼ å›¾ç‰‡
    """
    vec1 = group.iloc[0][feature_cols].values
    vec2 = group.iloc[1][feature_cols].values

    fused = np.concatenate([vec1, vec2], axis=0)

    return pd.Series(fused, name=group["main_id"].iloc[0])
#

merged_features = selected_df.groupby("main_id").apply(fuse_features)

features = np.stack(merged_features.values)
piece_ids = merged_features.index.to_numpy()

print(f"âœ… æ¯ä»¶é™¶ç‰‡èåˆåçš„ç‰¹å¾ç»´åº¦: {features.shape}")

# ========= 6. æ‰‹åŠ¨è®¾ç½®èšç±»æ•° =========
N_CLUSTERS = 200   # ğŸ‘ˆ ä½ æƒ³è¦çš„èšç±»æ•°é‡
N_CLUSTERS = 20

print(f"ğŸ¯ ä½¿ç”¨æ‰‹åŠ¨è®¾ç½®çš„èšç±»æ•°: {N_CLUSTERS}")

best_k = min(N_CLUSTERS, len(piece_ids))

# ========= 7. KMeans èšç±» =========
kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)
labels = kmeans.fit_predict(features)

# ä¿å­˜èšç±»ä¸­å¿ƒ
cluster_centers = kmeans.cluster_centers_
print(f"âœ… èšç±»ä¸­å¿ƒå½¢çŠ¶: {cluster_centers.shape}")

# ========= 8. é€‰æ‹©æ¯ä¸ªèšç±»çš„å…¸å‹æ ·æœ¬ï¼ˆè·ç¦»ä¸­å¿ƒæœ€è¿‘çš„æ ·æœ¬ï¼‰ =========
print("\nğŸ” æ­£åœ¨é€‰æ‹©æ¯ä¸ªèšç±»çš„å…¸å‹æ ·æœ¬ ...")
representative_samples = {}

for cluster_id in range(best_k):
    # è·å–è¯¥èšç±»çš„æ‰€æœ‰æ ·æœ¬
    cluster_indices = np.where(labels == cluster_id)[0]
    if len(cluster_indices) == 0:
        continue
    
    # è®¡ç®—æ¯ä¸ªæ ·æœ¬åˆ°ä¸­å¿ƒçš„è·ç¦»
    cluster_features = features[cluster_indices]
    center = cluster_centers[cluster_id]
    distances = np.linalg.norm(cluster_features - center, axis=1)
    
    # æ‰¾åˆ°è·ç¦»æœ€è¿‘çš„æ ·æœ¬
    closest_idx = cluster_indices[np.argmin(distances)]
    representative_samples[cluster_id] = {
        'piece_id': piece_ids[closest_idx],
        'distance': float(distances[np.argmin(distances)]),
        'index': int(closest_idx)
    }

print(f"âœ… å·²é€‰æ‹© {len(representative_samples)} ä¸ªèšç±»çš„å…¸å‹æ ·æœ¬")

# ========= 9. åˆ›å»ºè¾“å‡ºç›®å½• =========
for cluster_id in range(best_k):
    os.makedirs(os.path.join(OUTPUT_FOLDER, f"cluster_{cluster_id}"), exist_ok=True)

# ========= 10. æŒ‰èšç±»å¤åˆ¶å›¾åƒ =========
print("\nğŸ“ æ­£åœ¨å¤åˆ¶å›¾åƒåˆ°å¯¹åº” cluster ...")

for piece_id, label in tqdm(zip(piece_ids, labels), total=len(piece_ids)):
    files = selected_df[selected_df["main_id"] == piece_id]["filename"].values

    for f in files:
        src = os.path.join(IMAGE_ROOT, f)
        dst = os.path.join(OUTPUT_FOLDER, f"cluster_{label}", f)
        try:
            shutil.copy2(src, dst)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•å¤åˆ¶ {f}: {e}")

# ========= 11. ä¿å­˜èšç±»å…ƒæ•°æ® =========
import json
from pathlib import Path

cluster_metadata = {
    'n_clusters': best_k,
    'features_shape': features.shape,
    'cluster_centers': cluster_centers.tolist(),
    'representative_samples': representative_samples,
    'piece_ids': piece_ids.tolist(),
    'labels': labels.tolist()
}

meta_path = os.path.join(OUTPUT_FOLDER, "cluster_metadata.json")
with open(meta_path, 'w', encoding='utf-8') as f:
    json.dump(cluster_metadata, f, ensure_ascii=False, indent=2)

print(f"âœ… èšç±»å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {meta_path}")
print("\nğŸ‰ å®Œæˆï¼æ‰€æœ‰åŒä¸€é™¶ç‰‡çš„ä¸¤å¼ å›¾å·²æ”¾åœ¨åŒä¸€ç±»æ–‡ä»¶å¤¹ä¸­ã€‚")
